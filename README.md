# ddhh classifier
#  Clasificador de Texto para ProtecciÃ³n de Derechos Humanos

Este proyecto implementa un **sistema de clasificaciÃ³n de texto** que identifica posibles **vulneraciones a los Derechos Humanos (DDHH)** en mensajes digitales.  
Utiliza un esquema tipo **semÃ¡foro**:

- ğŸŸ¢ **VERDE:** Contenido normal  
- ğŸŸ¡ **AMARILLO:** Lenguaje potencialmente problemÃ¡tico  
- ğŸ”´ **ROJO:** Contenido que vulnera derechos (odio, amenazas, discriminaciÃ³n)

---

##  Modelos desarrollados

1. **TF-IDF + Random Forest:**  
   Modelo tradicional basado en frecuencia de palabras. RÃ¡pido, interpretable y liviano.

2. **Fine-Tuned BERT:**  
   Modelo Transformer ajustado para clasificaciÃ³n de discurso en inglÃ©s, con mayor sensibilidad contextual y semÃ¡ntica.

---

##  Estructura del proyecto

ddhh-classifier/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Datos originales
â”‚ â”œâ”€â”€ processed/ # Datos procesados
â”‚ â””â”€â”€ models/ # Modelos entrenados (no incluidos por tamaÃ±o)
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ exploration.ipynb # AnÃ¡lisis exploratorio
â”‚ â””â”€â”€ test.ipynb # ComparaciÃ³n de inferencia
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ Inference/
â”‚ â”‚ â”œâ”€â”€ inference_bert.py
â”‚ â”‚ â””â”€â”€ inference_tfidf_rf.py
â”‚ â”œâ”€â”€ models_training/
â”‚ â”‚ â”œâ”€â”€ model_training_bert.py
â”‚ â”‚ â””â”€â”€ model_training_TF-IDF_RF.py
â”‚ â”œâ”€â”€ data_preprocessing.py
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ test.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md


---

## âš™ï¸ InstalaciÃ³n del entorno

```bash
# Clonar el repositorio
git clone https://github.com/vdgaravitol/ddhh-classifier.git
cd ddhh-classifier

# Crear entorno virtual
python -m venv venv
venv\Scripts\activate   # Windows
# o
source venv/bin/activate  # Linux/Mac

# Instalar dependencias
pip install -r requirements.txt


#Uso de los modelos
# Inferencia con BERT
python src/Inference/inference_bert.py

# Inferencia con TF-IDF + Random Forest
python src/Inference/inference_tfidf_rf.py

Tras comparar ambos enfoques, el modelo BERT fine-tuned fue seleccionado como modelo principal por su mayor sensibilidad semÃ¡ntica y capacidad para identificar lenguaje ambiguo o implÃ­citamente violento.
Esto lo hace mÃ¡s adecuado en contextos de ProtecciÃ³n de Derechos Humanos, donde los falsos negativos (mensajes daÃ±inos no detectados) tienen un costo Ã©tico elevado.

El modelo TF-IDF + Random Forest se conserva como baseline liviano y explicable, Ãºtil para auditorÃ­as o entornos con menos recursos.

âœ… Modelo final elegido: Fine-Tuned BERT
ğŸ¯ JustificaciÃ³n: mejor contexto lingÃ¼Ã­stico, mayor recall y precisiÃ³n Ã©tica.

âš–ï¸ Consideraciones Ã©ticas

Los modelos pueden reflejar sesgos del dataset de origen.

Deben usarse como herramientas de apoyo, no como reemplazo de evaluaciÃ³n humana.

